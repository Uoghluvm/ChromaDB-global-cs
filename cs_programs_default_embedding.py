#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CS Programs ChromaDB Query Tool - ä½¿ç”¨é»˜è®¤åµŒå…¥æ¨¡å‹
ä¸éœ€è¦APIå¯†é’¥ï¼Œä½¿ç”¨ChromaDBè‡ªå¸¦çš„é»˜è®¤åµŒå…¥å‡½æ•°

ä½œè€…: Assistant
æ—¥æœŸ: 2025-09-16
"""

import pandas as pd
import chromadb
from chromadb.utils import embedding_functions
import json
import os
from pprint import pprint
from typing import List, Dict, Any

class CSProgramsDB:
    """CSé¡¹ç›®æ•°æ®åº“æŸ¥è¯¢ç±»"""
    
    def __init__(self, db_path: str = "vectors", collection_name: str = "cs_programs_default"):
        """
        åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        
        Args:
            db_path: æ•°æ®åº“è·¯å¾„
            collection_name: é›†åˆåç§°
        """
        self.db_path = db_path
        self.collection_name = collection_name
        self.client = None
        self.collection = None
        self.embedding_function = None
        
        self._initialize_db()
    
    def _initialize_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“å’ŒåµŒå…¥å‡½æ•°"""
        try:
            # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
            self.client = chromadb.PersistentClient(path=self.db_path)
            
            # ä½¿ç”¨ChromaDBé»˜è®¤åµŒå…¥å‡½æ•°ï¼ˆä¸éœ€è¦APIï¼‰
            self.embedding_function = embedding_functions.DefaultEmbeddingFunction()
            
            print(f"âœ… æˆåŠŸåˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯ï¼Œæ•°æ®åº“è·¯å¾„: {self.db_path}")
            print(f"âœ… ä½¿ç”¨é»˜è®¤åµŒå…¥å‡½æ•°: {type(self.embedding_function).__name__}")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def process_admission_data(self, admission_data_str: str) -> str:
        """å¤„ç†å½•å–æ•°æ®å­—ç¬¦ä¸²"""
        if not admission_data_str or admission_data_str == 'null':
            return "æš‚æ— å½•å–æ¡ˆä¾‹æ•°æ®"
        
        try:
            # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„åˆ—è¡¨è½¬æ¢
            data_str = admission_data_str.replace("'", '"')
            data_list = json.loads(data_str)
            
            cases = []
            for case in data_list:
                case_text = f"å½•å–æ¡ˆä¾‹({case.get('å½•å–æ—¶é—´', 'N/A')}): {case.get('å½•å–ç»“æœ', 'N/A')}ã€‚"
                case_text += f"ç”³è¯·è€…èƒŒæ™¯: {case.get('å­¦æ ¡ï¼ˆæ¡£æ¬¡ï¼‰', 'N/A')} {case.get('æœ¬ç§‘ä¸“ä¸š', 'N/A')}ä¸“ä¸šï¼Œ"
                case_text += f"GPA/Rank {case.get('GPA/Rank', 'N/A')}ï¼Œ"
                case_text += f"ç§‘ç ”ç»å† {case.get('ç§‘ç ”ç»å†', 'N/A')}ï¼Œ"
                case_text += f"å®ä¹ ç»å† {case.get('å®ä¹ ç»å†', 'N/A')}ã€‚"
                if case.get('å…¶ä»–ï¼ˆè¯­è¨€/æ¨èä¿¡ï¼‰'):
                    case_text += f"å…¶ä»–ä¿¡æ¯: {case.get('å…¶ä»–ï¼ˆè¯­è¨€/æ¨èä¿¡ï¼‰', '')}"
                cases.append(case_text)
            
            return " ".join(cases)
        except (json.JSONDecodeError, TypeError, AttributeError):
            return f"å½•å–æ•°æ®: {admission_data_str}"
    
    def create_document_text(self, row: pd.Series) -> str:
        """åˆ›å»ºç”¨äºè¯­ä¹‰æœç´¢çš„å¯Œæ–‡æœ¬æ–‡æ¡£"""
        admission_text = self.process_admission_data(row['admission_data'])
        
        document = f"""
é¡¹ç›®åç§°: {row['program_name']}
æ‰€å±å¤§å­¦: {row['university']}
åœ°åŒº: {row['region']}
é¡¹ç›®ç­‰çº§: {row['tier']}
å­¦åˆ¶: {row['duration']}
æˆè¯¾è¯­è¨€: {row['language']}
å­¦ä½ç±»å‹: {row['degree_type']}

é¡¹ç›®ä¼˜ç‚¹: {row['pros']}

é¡¹ç›®ç¼ºç‚¹: {row['cons']}

æ‹›ç”Ÿåå¥½: {row['admission_preference']}

ç”³è¯·æ³¨æ„äº‹é¡¹: {row['application_notes']}

å¥–å­¦é‡‘ä¿¡æ¯: {row['scholarship']}

è¿‡å¾€å½•å–æ¡ˆä¾‹: {admission_text}

å…¶ä»–ä¿¡æ¯: {row['other_info']} {row['other_notes']}
        """
        return document.strip()
    
    def load_and_process_data(self, csv_path: str = "global_cs_programs.csv") -> tuple:
        """åŠ è½½å’Œå¤„ç†CSVæ•°æ®"""
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        
        # è¯»å–CSVæ•°æ®
        df = pd.read_csv(csv_path).fillna('')
        print(f"ğŸ“Š è¯»å–åˆ° {len(df)} ä¸ªCSé¡¹ç›®")
        
        documents = []
        metadatas = []
        ids = []
        
        print("ğŸ”„ å¤„ç†é¡¹ç›®æ•°æ®...")
        
        for index, row in df.iterrows():
            # åˆ›å»ºæ–‡æ¡£æ–‡æœ¬
            doc_text = self.create_document_text(row)
            documents.append(doc_text)
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = {
                'program_name': str(row['program_name']),
                'university': str(row['university']),
                'region': str(row['region']),
                'tier': str(row['tier']),
                'duration': str(row['duration']),
                'language': str(row['language']),
                'degree_type': str(row['degree_type']),
                'internship_required': True if str(row['internship_required']).strip() == 'æ˜¯' else False,
                'thesis_required': True if str(row['thesis_required']).strip() == 'æ˜¯' else False,
                'admission_data_count': int(row['admission_data_count']) if str(row['admission_data_count']).isdigit() else 0
            }
            metadatas.append(metadata)
            
            # åˆ›å»ºå”¯ä¸€ID
            ids.append(f"program_{index}")
        
        print(f"âœ… æˆåŠŸå¤„ç† {len(documents)} ä¸ªé¡¹ç›®")
        return documents, metadatas, ids
    
    def create_collection(self, documents: List[str], metadatas: List[Dict], ids: List[str], 
                         recreate: bool = True) -> None:
        """åˆ›å»ºæˆ–é‡æ–°åˆ›å»ºé›†åˆ"""
        
        # åˆ é™¤ç°æœ‰é›†åˆï¼ˆå¦‚æœå­˜åœ¨ä¸”éœ€è¦é‡æ–°åˆ›å»ºï¼‰
        if recreate:
            try:
                self.client.delete_collection(name=self.collection_name)
                print(f"ğŸ—‘ï¸ åˆ é™¤ç°æœ‰é›†åˆ: {self.collection_name}")
            except:
                print(f"â„¹ï¸ é›†åˆ {self.collection_name} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°é›†åˆ")
        
        # åˆ›å»ºæ–°é›†åˆ
        self.collection = self.client.create_collection(
            name=self.collection_name,
            embedding_function=self.embedding_function
        )
        print(f"âœ… åˆ›å»ºé›†åˆ: {self.collection_name}")
        
        # æ‰¹é‡æ·»åŠ æ•°æ®
        batch_size = 10
        total_batches = (len(documents) + batch_size - 1) // batch_size
        
        print(f"ğŸ“¦ åˆ† {total_batches} æ‰¹æ¬¡æ·»åŠ æ•°æ®ï¼Œæ¯æ‰¹ {batch_size} ä¸ªé¡¹ç›®")
        
        for i in range(0, len(documents), batch_size):
            batch_docs = documents[i:i+batch_size]
            batch_ids = ids[i:i+batch_size]
            batch_metadata = metadatas[i:i+batch_size]
            
            batch_num = (i // batch_size) + 1
            
            try:
                self.collection.add(
                    documents=batch_docs,
                    metadatas=batch_metadata,
                    ids=batch_ids
                )
                print(f"âœ… æ‰¹æ¬¡ {batch_num}/{total_batches} æ·»åŠ æˆåŠŸ")
                
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {batch_num} æ·»åŠ å¤±è´¥: {str(e)}")
                break
        
        print(f"ğŸ‰ é›†åˆåˆ›å»ºå®Œæˆï¼ŒåŒ…å« {self.collection.count()} ä¸ªé¡¹ç›®")
    
    def get_existing_collection(self) -> bool:
        """è·å–ç°æœ‰é›†åˆ"""
        try:
            self.collection = self.client.get_collection(
                name=self.collection_name,
                embedding_function=self.embedding_function
            )
            print(f"âœ… è¿æ¥åˆ°ç°æœ‰é›†åˆ '{self.collection_name}'ï¼ŒåŒ…å« {self.collection.count()} ä¸ªé¡¹ç›®")
            return True
        except ValueError:
            print(f"âš ï¸ é›†åˆ '{self.collection_name}' ä¸å­˜åœ¨")
            available_collections = self.client.list_collections()
            if available_collections:
                print("ğŸ“‹ å¯ç”¨é›†åˆ:", [col.name for col in available_collections])
            return False
    
    def query_programs(self, query_text: str, n_results: int = 5, 
                      where_filter: Dict = None) -> Dict[str, Any]:
        """æŸ¥è¯¢é¡¹ç›®"""
        if not self.collection:
            raise ValueError("é›†åˆæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆåˆ›å»ºæˆ–è¿æ¥åˆ°é›†åˆ")
        
        try:
            results = self.collection.query(
                query_texts=[query_text],
                n_results=n_results,
                where=where_filter
            )
            return results
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            return {}
    
    def print_query_results(self, results: Dict[str, Any], query_description: str = ""):
        """æ‰“å°æŸ¥è¯¢ç»“æœ"""
        if not results or not results.get('documents') or not results['documents'][0]:
            print(f"\nğŸ¤· {query_description} - æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç»“æœ")
            return
        
        print(f"\nğŸ” {query_description}")
        print("=" * 50)
        
        for i, (doc, metadata, distance) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0],
            results['distances'][0]
        )):
            print(f"\nğŸ“‹ ç»“æœ {i+1} (ç›¸ä¼¼åº¦: {1-distance:.3f}):")
            print(f"  é¡¹ç›®: {metadata.get('program_name', 'N/A')}")
            print(f"  å¤§å­¦: {metadata.get('university', 'N/A')}")
            print(f"  åœ°åŒº: {metadata.get('region', 'N/A')}")
            print(f"  ç­‰çº§: {metadata.get('tier', 'N/A')}")
            print(f"  å­¦åˆ¶: {metadata.get('duration', 'N/A')}")
            print(f"  è¯­è¨€: {metadata.get('language', 'N/A')}")
            if metadata.get('admission_data_count', 0) > 0:
                print(f"  å½•å–æ¡ˆä¾‹æ•°: {metadata['admission_data_count']}")
    
    def get_collection_stats(self):
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        if not self.collection:
            print("âŒ é›†åˆæœªåˆå§‹åŒ–")
            return
        
        all_data = self.collection.get()
        total_count = len(all_data['metadatas'])
        
        print(f"\nğŸ“Š é›†åˆç»Ÿè®¡ä¿¡æ¯")
        print("=" * 30)
        print(f"æ€»é¡¹ç›®æ•°: {total_count}")
        
        # æŒ‰åœ°åŒºç»Ÿè®¡
        regions = [meta['region'] for meta in all_data['metadatas']]
        region_counts = {}
        for region in regions:
            region_counts[region] = region_counts.get(region, 0) + 1
        
        print(f"\nğŸ“ æŒ‰åœ°åŒºåˆ†å¸ƒ:")
        for region, count in sorted(region_counts.items()):
            print(f"  {region}: {count} ä¸ªé¡¹ç›®")
        
        # æŒ‰ç­‰çº§ç»Ÿè®¡
        tiers = [meta['tier'] for meta in all_data['metadatas']]
        tier_counts = {}
        for tier in tiers:
            tier_counts[tier] = tier_counts.get(tier, 0) + 1
        
        print(f"\nğŸ† æŒ‰ç­‰çº§åˆ†å¸ƒ:")
        for tier, count in sorted(tier_counts.items()):
            print(f"  {tier}: {count} ä¸ªé¡¹ç›®")
        
        # è®ºæ–‡è¦æ±‚ç»Ÿè®¡
        thesis_required = sum(1 for meta in all_data['metadatas'] if meta['thesis_required'])
        print(f"\nğŸ“ éœ€è¦è®ºæ–‡çš„é¡¹ç›®: {thesis_required}/{total_count}")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç”¨æ³•"""
    print("ğŸš€ CS Programs ChromaDB Query Tool (é»˜è®¤åµŒå…¥æ¨¡å‹)")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = CSProgramsDB()
    
    # å°è¯•è¿æ¥ç°æœ‰é›†åˆ
    if not db.get_existing_collection():
        print("\nğŸ”„ æœªæ‰¾åˆ°ç°æœ‰é›†åˆï¼Œå¼€å§‹åˆ›å»ºæ–°é›†åˆ...")
        
        # åŠ è½½å’Œå¤„ç†æ•°æ®
        try:
            documents, metadatas, ids = db.load_and_process_data()
            
            # åˆ›å»ºé›†åˆ
            db.create_collection(documents, metadatas, ids)
            
        except FileNotFoundError as e:
            print(f"âŒ {e}")
            print("è¯·ç¡®ä¿ 'global_cs_programs.csv' æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹")
            return
        except Exception as e:
            print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
            return
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    db.get_collection_stats()
    
    # æ‰§è¡Œç¤ºä¾‹æŸ¥è¯¢
    print(f"\nğŸ” æ‰§è¡Œç¤ºä¾‹æŸ¥è¯¢")
    print("=" * 40)
    
    # æŸ¥è¯¢1: çŸ­å­¦åˆ¶é¡¹ç›®
    results1 = db.query_programs(
        query_text="å­¦åˆ¶çŸ­ å¿«é€Ÿæ¯•ä¸š æ—¶é—´ç´§å‡‘",
        n_results=5,
        where_filter={"duration": {"$in": ["9ä¸ªæœˆ", "10ä¸ªæœˆ", "11ä¸ªæœˆ", "12ä¸ªæœˆ", "1å¹´", "ä¸€å¹´"]}}
    )
    db.print_query_results(results1, "çŸ­å­¦åˆ¶é¡¹ç›® (1å¹´ä»¥å†…)")
    
    # æŸ¥è¯¢2: é¡¶çº§é¡¹ç›®
    results2 = db.query_programs(
        query_text="é¡¶çº§å¤§å­¦ è®¡ç®—æœºç§‘å­¦ äººå·¥æ™ºèƒ½",
        n_results=5,
        where_filter={"tier": {"$in": ["T0", "T1"]}}
    )
    db.print_query_results(results2, "é¡¶çº§é¡¹ç›® (T0/T1)")
    
    # æŸ¥è¯¢3: è‹±å›½é¡¹ç›®
    results3 = db.query_programs(
        query_text="è‹±å›½ å½•å–å‹å¥½ ç”³è¯·å»ºè®®",
        n_results=3,
        where_filter={"region": "è‹±å›½"}
    )
    db.print_query_results(results3, "è‹±å›½CSé¡¹ç›®")
    
    # æŸ¥è¯¢4: ä¸éœ€è¦è®ºæ–‡çš„é¡¹ç›®
    results4 = db.query_programs(
        query_text="ä¸éœ€è¦è®ºæ–‡ coursework æˆè¯¾å‹",
        n_results=3,
        where_filter={"thesis_required": False}
    )
    db.print_query_results(results4, "ä¸éœ€è¦è®ºæ–‡çš„é¡¹ç›®")
    
    print(f"\nâœ… æŸ¥è¯¢æ¼”ç¤ºå®Œæˆ!")
    print(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("- å¯ä»¥ä¿®æ”¹ main() å‡½æ•°ä¸­çš„æŸ¥è¯¢æ¥æµ‹è¯•ä¸åŒæœç´¢")
    print("- æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æŸ¥è¯¢")
    print("- å¯ä»¥ä½¿ç”¨ where_filter è¿›è¡Œç²¾ç¡®ç­›é€‰")
    print("- é»˜è®¤åµŒå…¥æ¨¡å‹æ— éœ€APIå¯†é’¥ï¼Œä½†æ•ˆæœå¯èƒ½ä¸å¦‚ä¸“ä¸šæ¨¡å‹")


if __name__ == "__main__":
    main()
