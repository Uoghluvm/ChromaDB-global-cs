{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54437f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries and setup\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from pprint import pprint\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e332e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (76, 18)\n",
      "\n",
      "Column names:\n",
      "['program_name',\n",
      " 'university',\n",
      " 'region',\n",
      " 'tier',\n",
      " 'duration',\n",
      " 'language',\n",
      " 'degree_type',\n",
      " 'internship_required',\n",
      " 'thesis_required',\n",
      " 'scholarship',\n",
      " 'other_info',\n",
      " 'pros',\n",
      " 'cons',\n",
      " 'admission_preference',\n",
      " 'admission_data_count',\n",
      " 'admission_data',\n",
      " 'application_notes',\n",
      " 'other_notes']\n",
      "\n",
      "First 2 rows preview:\n",
      "     program_name university region tier\n",
      "0   Cambridge ACS  Cambridge     è‹±å›½   T0\n",
      "1  Cambridge MLMI  Cambridge     è‹±å›½   T0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Read CS programs CSV data\n",
    "# Using pandas for better JSON handling, then convert to polars if needed\n",
    "df = pd.read_csv(\"global_cs_programs.csv\").fillna('')\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(\"\\nColumn names:\")\n",
    "pprint(list(df.columns))\n",
    "print(\"\\nFirst 2 rows preview:\")\n",
    "print(df[['program_name', 'university', 'region', 'tier']].head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b9058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB and embedding function initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize ChromaDB with persistent storage\n",
    "chroma_client = chromadb.PersistentClient(path=\"vectors\")\n",
    "\n",
    "# Initialize Google Gemini embedding function\n",
    "google_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
    "    api_key=\"API_KEY\",\n",
    "    model_name=\"gemini-embedding-001\"\n",
    ")\n",
    "\n",
    "print(\"ChromaDB and embedding function initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a659c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data preprocessing and document creation\n",
    "def process_admission_data(admission_data_str):\n",
    "    \"\"\"Convert admission_data string to readable text\"\"\"\n",
    "    if not admission_data_str or admission_data_str == 'null':\n",
    "        return \"æš‚æ— å½•å–æ¡ˆä¾‹æ•°æ®\"\n",
    "    \n",
    "    try:\n",
    "        # Handle string format list conversion\n",
    "        data_str = admission_data_str.replace(\"'\", \"\\\"\")\n",
    "        data_list = json.loads(data_str)\n",
    "        \n",
    "        cases = []\n",
    "        for case in data_list:\n",
    "            case_text = f\"å½•å–æ¡ˆä¾‹({case.get('å½•å–æ—¶é—´', 'N/A')}): {case.get('å½•å–ç»“æœ', 'N/A')}ã€‚\"\n",
    "            case_text += f\"ç”³è¯·è€…èƒŒæ™¯: {case.get('å­¦æ ¡ï¼ˆæ¡£æ¬¡ï¼‰', 'N/A')} {case.get('æœ¬ç§‘ä¸“ä¸š', 'N/A')}ä¸“ä¸šï¼Œ\"\n",
    "            case_text += f\"GPA/Rank {case.get('GPA/Rank', 'N/A')}ï¼Œ\"\n",
    "            case_text += f\"ç§‘ç ”ç»å† {case.get('ç§‘ç ”ç»å†', 'N/A')}ï¼Œ\"\n",
    "            case_text += f\"å®ä¹ ç»å† {case.get('å®ä¹ ç»å†', 'N/A')}ã€‚\"\n",
    "            if case.get('å…¶ä»–ï¼ˆè¯­è¨€/æ¨èä¿¡ï¼‰'):\n",
    "                case_text += f\"å…¶ä»–ä¿¡æ¯: {case.get('å…¶ä»–ï¼ˆè¯­è¨€/æ¨èä¿¡ï¼‰', '')}\"\n",
    "            cases.append(case_text)\n",
    "        \n",
    "        return \" \".join(cases)\n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        return f\"å½•å–æ•°æ®: {admission_data_str}\"\n",
    "\n",
    "def create_document_text(row):\n",
    "    \"\"\"Create rich document text for semantic search\"\"\"\n",
    "    admission_text = process_admission_data(row['admission_data'])\n",
    "    \n",
    "    document = f\"\"\"\n",
    "é¡¹ç›®åç§°: {row['program_name']}\n",
    "æ‰€å±å¤§å­¦: {row['university']}\n",
    "åœ°åŒº: {row['region']}\n",
    "é¡¹ç›®ç­‰çº§: {row['tier']}\n",
    "å­¦åˆ¶: {row['duration']}\n",
    "æˆè¯¾è¯­è¨€: {row['language']}\n",
    "å­¦ä½ç±»å‹: {row['degree_type']}\n",
    "\n",
    "é¡¹ç›®ä¼˜ç‚¹: {row['pros']}\n",
    "\n",
    "é¡¹ç›®ç¼ºç‚¹: {row['cons']}\n",
    "\n",
    "æ‹›ç”Ÿåå¥½: {row['admission_preference']}\n",
    "\n",
    "ç”³è¯·æ³¨æ„äº‹é¡¹: {row['application_notes']}\n",
    "\n",
    "å¥–å­¦é‡‘ä¿¡æ¯: {row['scholarship']}\n",
    "\n",
    "è¿‡å¾€å½•å–æ¡ˆä¾‹: {admission_text}\n",
    "\n",
    "å…¶ä»–ä¿¡æ¯: {row['other_info']} {row['other_notes']}\n",
    "    \"\"\"\n",
    "    return document.strip()\n",
    "\n",
    "print(\"Data processing functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f304d866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 76 CS programs...\n",
      "Processed 76 programs successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Process all data for ChromaDB\n",
    "documents = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "\n",
    "print(f\"Processing {len(df)} CS programs...\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Create document text\n",
    "    doc_text = create_document_text(row)\n",
    "    documents.append(doc_text)\n",
    "    \n",
    "    # Create metadata for filtering\n",
    "    metadata = {\n",
    "        'program_name': str(row['program_name']),\n",
    "        'university': str(row['university']),\n",
    "        'region': str(row['region']),\n",
    "        'tier': str(row['tier']),\n",
    "        'duration': str(row['duration']),\n",
    "        'language': str(row['language']),\n",
    "        'degree_type': str(row['degree_type']),\n",
    "        'internship_required': True if str(row['internship_required']).strip() == 'æ˜¯' else False,\n",
    "        'thesis_required': True if str(row['thesis_required']).strip() == 'æ˜¯' else False,\n",
    "        'admission_data_count': int(row['admission_data_count']) if str(row['admission_data_count']).isdigit() else 0\n",
    "    }\n",
    "    metadatas.append(metadata)\n",
    "    \n",
    "    # Create unique ID\n",
    "    ids.append(f\"program_{index}\")\n",
    "\n",
    "print(f\"Processed {len(documents)} programs successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963fd9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing collection to delete\n",
      "Created collection: cs_programs_collection\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create ChromaDB collection\n",
    "collection_name = \"cs_programs_collection\"\n",
    "\n",
    "# Delete existing collection if it exists\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "    print(f\"Deleted existing collection: {collection_name}\")\n",
    "except:\n",
    "    print(\"No existing collection to delete\")\n",
    "\n",
    "# Create new collection with embedding function\n",
    "collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=google_ef\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805f0f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 76 programs in 8 batches of 10\n",
      "Processing batch 1/8\n",
      "âœ“ Added batch 1\n",
      "Processing batch 2/8\n",
      "âœ“ Added batch 2\n",
      "Processing batch 3/8\n",
      "âœ“ Added batch 3\n",
      "Processing batch 4/8\n",
      "âœ“ Added batch 4\n",
      "Processing batch 5/8\n",
      "âœ“ Added batch 5\n",
      "Processing batch 6/8\n",
      "âœ“ Added batch 6\n",
      "Processing batch 7/8\n",
      "âœ“ Added batch 7\n",
      "Processing batch 8/8\n",
      "âœ“ Added batch 8\n",
      "\n",
      "Collection created with 76 programs\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Add data to collection in batches\n",
    "batch_size = 10\n",
    "total_batches = (len(documents) + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"Adding {len(documents)} programs in {total_batches} batches of {batch_size}\")\n",
    "\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    batch_docs = documents[i:i+batch_size]\n",
    "    batch_ids = ids[i:i+batch_size]\n",
    "    batch_metadata = metadatas[i:i+batch_size]\n",
    "    \n",
    "    batch_num = (i // batch_size) + 1\n",
    "    \n",
    "    print(f\"Processing batch {batch_num}/{total_batches}\")\n",
    "    \n",
    "    try:\n",
    "        collection.add(\n",
    "            documents=batch_docs,\n",
    "            metadatas=batch_metadata,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "        print(f\"âœ“ Added batch {batch_num}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error in batch {batch_num}: {str(e)}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nCollection created with {collection.count()} programs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9302ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Semantic Search with Filters ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Testing Semantic Search with Filters ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Query 1: Find TOP-TIER programs suitable for mainland Chinese students\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m results1 \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m      6\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mé™†æœ¬èƒŒæ™¯ç”³è¯· å½•å–æ¡ˆä¾‹ å‹å¥½\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m     n_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m      8\u001b[0m     where\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$and\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtier\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$in\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT1\u001b[39m\u001b[38;5;124m\"\u001b[39m]}}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madmission_data_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$gt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m}}]}\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ” Query: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT0/T1çº§åˆ«ä¸”æœ‰é™†æœ¬å½•å–æ¡ˆä¾‹çš„é¡¹ç›®\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (doc, metadata, distance) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m     13\u001b[0m     results1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \n\u001b[0;32m     14\u001b[0m     results1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \n\u001b[0;32m     15\u001b[0m     results1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m )):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 8: Test semantic search queries with filters\n",
    "print(\"\\n=== Testing Semantic Search with Filters ===\")\n",
    "\n",
    "# Query 1: Find TOP-TIER programs suitable for mainland Chinese students\n",
    "results1 = collection.query(\n",
    "    query_texts=[\"é™†æœ¬èƒŒæ™¯ç”³è¯· å½•å–æ¡ˆä¾‹ å‹å¥½\"],\n",
    "    n_results=5,\n",
    "    where={\"$and\": [{\"tier\": {\"$in\": [\"T0\", \"T1\"]}}, {\"admission_data_count\": {\"$gt\": 0}}]}\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ” Query: 'T0/T1çº§åˆ«ä¸”æœ‰é™†æœ¬å½•å–æ¡ˆä¾‹çš„é¡¹ç›®'\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results1['documents'][0], \n",
    "    results1['metadatas'][0], \n",
    "    results1['distances'][0]\n",
    ")):\n",
    "    print(f\"\\nğŸ“‹ Result {i+1} (ç›¸ä¼¼åº¦: {1-distance:.3f}):\")\n",
    "    print(f\"é¡¹ç›®: {metadata['program_name']}\")\n",
    "    print(f\"å¤§å­¦: {metadata['university']}\")\n",
    "    print(f\"åœ°åŒº: {metadata['region']}\")\n",
    "    print(f\"ç­‰çº§: {metadata['tier']}\")\n",
    "    print(f\"å­¦åˆ¶: {metadata['duration']}\")\n",
    "    print(f\"å½•å–æ¡ˆä¾‹æ•°: {metadata['admission_data_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066141d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Query: '1å¹´ä»¥å†…çš„çŸ­å­¦åˆ¶ä¼˜è´¨é¡¹ç›®'\n",
      "\n",
      "ğŸ“‹ Result 1:\n",
      "é¡¹ç›®: Cambridge ACS\n",
      "å­¦åˆ¶: 9ä¸ªæœˆ\n",
      "å¤§å­¦: Cambridge\n",
      "ç­‰çº§: T0\n",
      "åœ°åŒº: è‹±å›½\n",
      "\n",
      "ğŸ“‹ Result 2:\n",
      "é¡¹ç›®: NUS DSML\n",
      "å­¦åˆ¶: 1å¹´\n",
      "å¤§å­¦: NUS\n",
      "ç­‰çº§: T2\n",
      "åœ°åŒº: æ–°åŠ å¡\n",
      "\n",
      "ğŸ“‹ Result 3:\n",
      "é¡¹ç›®: Edinburgh CS\n",
      "å­¦åˆ¶: 1å¹´\n",
      "å¤§å­¦: Edinburgh\n",
      "ç­‰çº§: T1.5\n",
      "åœ°åŒº: è‹±å›½\n",
      "\n",
      "ğŸ“‹ Result 4:\n",
      "é¡¹ç›®: IC AIML\n",
      "å­¦åˆ¶: 1å¹´\n",
      "å¤§å­¦: IC\n",
      "ç­‰çº§: T1\n",
      "åœ°åŒº: è‹±å›½\n",
      "\n",
      "ğŸ“‹ Result 5:\n",
      "é¡¹ç›®: IC AC\n",
      "å­¦åˆ¶: 1å¹´\n",
      "å¤§å­¦: IC\n",
      "ç­‰çº§: T1\n",
      "åœ°åŒº: è‹±å›½\n",
      "\n",
      "ğŸ” Query: 'æœ‰å¥–å­¦é‡‘æœºä¼šçš„ä¼˜è´¨é¡¹ç›®'\n",
      "\n",
      "ğŸ“‹ Result 1:\n",
      "é¡¹ç›®: EITæ¬§ç›Ÿå¥–å­¦é‡‘\n",
      "å¤§å­¦: EITæ¬§ç›Ÿå¥–å­¦é‡‘\n",
      "åœ°åŒº: æœªåˆ†ç±»\n",
      "ç­‰çº§: T1.5\n",
      "\n",
      "ğŸ“‹ Result 2:\n",
      "é¡¹ç›®: EMæ¬§ç›Ÿå¥–å­¦é‡‘\n",
      "å¤§å­¦: EMæ¬§ç›Ÿå¥–å­¦é‡‘\n",
      "åœ°åŒº: æœªåˆ†ç±»\n",
      "ç­‰çº§: T1.5\n",
      "\n",
      "ğŸ“‹ Result 3:\n",
      "é¡¹ç›®: KAUST CS Msc\n",
      "å¤§å­¦: KAUST\n",
      "åœ°åŒº: æ—¥éŸ©/å…¶ä»–\n",
      "ç­‰çº§: TX\n",
      "\n",
      "ğŸ“‹ Result 4:\n",
      "é¡¹ç›®: TUE CS\n",
      "å¤§å­¦: TUE\n",
      "åœ°åŒº: æ¬§é™†\n",
      "ç­‰çº§: T1.5\n",
      "\n",
      "ğŸ“‹ Result 5:\n",
      "é¡¹ç›®: Aalto CS\n",
      "å¤§å­¦: Aalto\n",
      "åœ°åŒº: æ¬§é™†\n",
      "ç­‰çº§: T1\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: More targeted queries with duration filter\n",
    "# Query 2: Short duration programs (filter for programs â‰¤ 12 months)\n",
    "results2 = collection.query(\n",
    "    query_texts=[\"å­¦åˆ¶çŸ­ å¿«é€Ÿæ¯•ä¸š æ—¶é—´ç´§å‡‘\"],\n",
    "    n_results=5,\n",
    "    where={\"duration\": {\"$in\": [\"9ä¸ªæœˆ\", \"10ä¸ªæœˆ\", \"11ä¸ªæœˆ\", \"12ä¸ªæœˆ\", \"1å¹´\", \"ä¸€å¹´\"]}}\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ” Query: '1å¹´ä»¥å†…çš„çŸ­å­¦åˆ¶ä¼˜è´¨é¡¹ç›®'\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results2['documents'][0], \n",
    "    results2['metadatas'][0], \n",
    "    results2['distances'][0]\n",
    ")):\n",
    "    print(f\"\\nğŸ“‹ Result {i+1}:\")\n",
    "    print(f\"é¡¹ç›®: {metadata['program_name']}\")\n",
    "    print(f\"å­¦åˆ¶: {metadata['duration']}\")\n",
    "    print(f\"å¤§å­¦: {metadata['university']}\")\n",
    "    print(f\"ç­‰çº§: {metadata['tier']}\")\n",
    "    print(f\"åœ°åŒº: {metadata['region']}\")\n",
    "\n",
    "# Query 3: Scholarship opportunities (exclude programs with \"è¾ƒéš¾è·å¾—\" scholarships)\n",
    "results3 = collection.query(\n",
    "    query_texts=[\"å¥–å­¦é‡‘ èµ„åŠ© ç»æµæ”¯æŒ å®¹æ˜“ç”³è¯·\"],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ” Query: 'æœ‰å¥–å­¦é‡‘æœºä¼šçš„ä¼˜è´¨é¡¹ç›®'\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results3['documents'][0], \n",
    "    results3['metadatas'][0], \n",
    "    results3['distances'][0]\n",
    ")):\n",
    "    print(f\"\\nğŸ“‹ Result {i+1}:\")\n",
    "    print(f\"é¡¹ç›®: {metadata['program_name']}\")\n",
    "    print(f\"å¤§å­¦: {metadata['university']}\")\n",
    "    print(f\"åœ°åŒº: {metadata['region']}\")\n",
    "    print(f\"ç­‰çº§: {metadata['tier']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e8958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced Filtering ===\n",
      "\n",
      "ğŸ¯ Filter: è‹±å›½T0çº§åˆ«é¡¹ç›®\n",
      "\n",
      "ğŸ“‹ Result 1:\n",
      "é¡¹ç›®: UCL CSML MSc\n",
      "å¤§å­¦: UCL\n",
      "å­¦ä½ç±»å‹: \n",
      "æ˜¯å¦éœ€è¦è®ºæ–‡: å¦\n",
      "\n",
      "ğŸ“‹ Result 2:\n",
      "é¡¹ç›®: Cambridge MLMI\n",
      "å¤§å­¦: Cambridge\n",
      "å­¦ä½ç±»å‹: Mphil\n",
      "æ˜¯å¦éœ€è¦è®ºæ–‡: æ˜¯\n",
      "\n",
      "ğŸ“‹ Result 3:\n",
      "é¡¹ç›®: Cambridge ACS\n",
      "å¤§å­¦: Cambridge\n",
      "å­¦ä½ç±»å‹: Mphil\n",
      "æ˜¯å¦éœ€è¦è®ºæ–‡: æ˜¯\n",
      "\n",
      "ğŸ“‹ Result 4:\n",
      "é¡¹ç›®: Oxford ACS\n",
      "å¤§å­¦: Oxford\n",
      "å­¦ä½ç±»å‹: MSc in Advanced Computer Science\n",
      "æ˜¯å¦éœ€è¦è®ºæ–‡: æ˜¯\n",
      "\n",
      "ğŸ¯ Filter: è‹±å›½æœ‰å½•å–æ•°æ®çš„é¡¹ç›®\n",
      "\n",
      "ğŸ“‹ Result 1:\n",
      "é¡¹ç›®: IC AC\n",
      "å¤§å­¦: IC\n",
      "ç­‰çº§: T1\n",
      "å½•å–æ¡ˆä¾‹æ•°: 3\n",
      "\n",
      "ğŸ“‹ Result 2:\n",
      "é¡¹ç›®: Oxford ACS\n",
      "å¤§å­¦: Oxford\n",
      "ç­‰çº§: T0\n",
      "å½•å–æ¡ˆä¾‹æ•°: 1\n",
      "\n",
      "ğŸ“‹ Result 3:\n",
      "é¡¹ç›®: UCL CGVI\n",
      "å¤§å­¦: UCL\n",
      "ç­‰çº§: T1.5\n",
      "å½•å–æ¡ˆä¾‹æ•°: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Advanced filtering with metadata\n",
    "print(\"\\n=== Advanced Filtering ===\")\n",
    "\n",
    "# Filter by region and tier with better query\n",
    "uk_t0_results = collection.query(\n",
    "    query_texts=[\"è®¡ç®—æœºç§‘å­¦ äººå·¥æ™ºèƒ½ æœºå™¨å­¦ä¹  é¡¶çº§é¡¹ç›®\"],\n",
    "    n_results=5,\n",
    "    where={\"$and\": [{\"region\": \"è‹±å›½\"}, {\"tier\": \"T0\"}]}\n",
    ")\n",
    "\n",
    "# Additional query: US programs with good admission data\n",
    "us_programs = collection.query(\n",
    "    query_texts=[\"è‹±å›½ å½•å–å‹å¥½ ç”³è¯·å»ºè®®\"],\n",
    "    n_results=3,\n",
    "    where={\"$and\": [{\"region\": \"è‹±å›½\"}, {\"admission_data_count\": {\"$gt\": 0}}]}\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯ Filter: è‹±å›½T0çº§åˆ«é¡¹ç›®\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    uk_t0_results['documents'][0], \n",
    "    uk_t0_results['metadatas'][0], \n",
    "    uk_t0_results['distances'][0]\n",
    ")):\n",
    "    print(f\"\\nğŸ“‹ Result {i+1}:\")\n",
    "    print(f\"é¡¹ç›®: {metadata['program_name']}\")\n",
    "    print(f\"å¤§å­¦: {metadata['university']}\")\n",
    "    print(f\"å­¦ä½ç±»å‹: {metadata['degree_type']}\")\n",
    "    print(f\"æ˜¯å¦éœ€è¦è®ºæ–‡: {'æ˜¯' if metadata['thesis_required'] else 'å¦'}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Filter: è‹±å›½æœ‰å½•å–æ•°æ®çš„é¡¹ç›®\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    us_programs['documents'][0], \n",
    "    us_programs['metadatas'][0], \n",
    "    us_programs['distances'][0]\n",
    ")):\n",
    "    print(f\"\\nğŸ“‹ Result {i+1}:\")\n",
    "    print(f\"é¡¹ç›®: {metadata['program_name']}\")\n",
    "    print(f\"å¤§å­¦: {metadata['university']}\")\n",
    "    print(f\"ç­‰çº§: {metadata['tier']}\")\n",
    "    print(f\"å½•å–æ¡ˆä¾‹æ•°: {metadata['admission_data_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fedf7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Specialized Queries ===\n",
      "\n",
      "ğŸ¯ ä¸éœ€è¦è®ºæ–‡çš„é¡¶çº§é¡¹ç›®:\n",
      "\n",
      "ğŸ“‹ Result 1:\n",
      "é¡¹ç›®: Aalto HCI\n",
      "å¤§å­¦: Aalto\n",
      "å­¦åˆ¶: \n",
      "ç­‰çº§: T1\n",
      "\n",
      "ğŸ“‹ Result 2:\n",
      "é¡¹ç›®: Edinburgh AI\n",
      "å¤§å­¦: Edinburgh\n",
      "å­¦åˆ¶: \n",
      "ç­‰çº§: T1\n",
      "\n",
      "ğŸ“‹ Result 3:\n",
      "é¡¹ç›®: UCL ML MSc\n",
      "å¤§å­¦: UCL\n",
      "å­¦åˆ¶: \n",
      "ç­‰çº§: T1\n",
      "\n",
      "ğŸ¯ éè‹±è¯­å›½å®¶çš„è‹±è¯­æˆè¯¾é¡¹ç›®:\n",
      "\n",
      "ğŸ“‹ Result 1:\n",
      "é¡¹ç›®: Uppsala CS\n",
      "å¤§å­¦: Uppsala\n",
      "åœ°åŒº: æ¬§é™†\n",
      "è¯­è¨€: EN\n",
      "\n",
      "ğŸ“‹ Result 2:\n",
      "é¡¹ç›®: EITæ¬§ç›Ÿå¥–å­¦é‡‘\n",
      "å¤§å­¦: EITæ¬§ç›Ÿå¥–å­¦é‡‘\n",
      "åœ°åŒº: æœªåˆ†ç±»\n",
      "è¯­è¨€: EN\n",
      "\n",
      "ğŸ“‹ Result 3:\n",
      "é¡¹ç›®: DTU AI\n",
      "å¤§å­¦: DTU\n",
      "åœ°åŒº: æ¬§é™†\n",
      "è¯­è¨€: EN\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Specialized queries for different needs\n",
    "print(\"\\n=== Specialized Queries ===\")\n",
    "\n",
    "# Query for programs without thesis requirement\n",
    "no_thesis_programs = collection.query(\n",
    "    query_texts=[\"ä¸éœ€è¦è®ºæ–‡ coursework æˆè¯¾å‹\"],\n",
    "    n_results=3,\n",
    "    where={\"$and\": [{\"thesis_required\": False}, {\"tier\": {\"$in\": [\"T0\", \"T1\"]}}]}\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯ ä¸éœ€è¦è®ºæ–‡çš„é¡¶çº§é¡¹ç›®:\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    no_thesis_programs['documents'][0], \n",
    "    no_thesis_programs['metadatas'][0], \n",
    "    no_thesis_programs['distances'][0]\n",
    ")):\n",
    "    print(f\"\\nğŸ“‹ Result {i+1}:\")\n",
    "    print(f\"é¡¹ç›®: {metadata['program_name']}\")\n",
    "    print(f\"å¤§å­¦: {metadata['university']}\")\n",
    "    print(f\"å­¦åˆ¶: {metadata['duration']}\")\n",
    "    print(f\"ç­‰çº§: {metadata['tier']}\")\n",
    "\n",
    "# Query for English-taught programs in non-English countries\n",
    "non_english_countries = collection.query(\n",
    "    query_texts=[\"è‹±è¯­æˆè¯¾ å›½é™…é¡¹ç›®\"],\n",
    "    n_results=3,\n",
    "    where={\"$and\": [\n",
    "        {\"language\": \"EN\"}, \n",
    "        {\"region\": {\"$nin\": [\"è‹±å›½\", \"æ¾³æ´²\", \"åŠ æ‹¿å¤§\"]}}\n",
    "    ]}\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯ éè‹±è¯­å›½å®¶çš„è‹±è¯­æˆè¯¾é¡¹ç›®:\")\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    non_english_countries['documents'][0], \n",
    "    non_english_countries['metadatas'][0], \n",
    "    non_english_countries['distances'][0]\n",
    ")):\n",
    "    print(f\"\\nğŸ“‹ Result {i+1}:\")\n",
    "    print(f\"é¡¹ç›®: {metadata['program_name']}\")\n",
    "    print(f\"å¤§å­¦: {metadata['university']}\")\n",
    "    print(f\"åœ°åŒº: {metadata['region']}\")\n",
    "    print(f\"è¯­è¨€: {metadata['language']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c9524c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Collection Statistics ===\n",
      "æ€»é¡¹ç›®æ•°: 76\n",
      "\n",
      "ğŸ“Š æŒ‰åœ°åŒºåˆ†å¸ƒ:\n",
      "  æ–°åŠ å¡: 7 ä¸ªé¡¹ç›®\n",
      "  æ—¥éŸ©/å…¶ä»–: 9 ä¸ªé¡¹ç›®\n",
      "  æœªåˆ†ç±»: 5 ä¸ªé¡¹ç›®\n",
      "  æ¬§é™†: 39 ä¸ªé¡¹ç›®\n",
      "  è‹±å›½: 12 ä¸ªé¡¹ç›®\n",
      "  é¦™æ¸¯: 4 ä¸ªé¡¹ç›®\n",
      "\n",
      "ğŸ“Š æŒ‰ç­‰çº§åˆ†å¸ƒ:\n",
      "  T0: 8 ä¸ªé¡¹ç›®\n",
      "  T0.5: 1 ä¸ªé¡¹ç›®\n",
      "  T1: 14 ä¸ªé¡¹ç›®\n",
      "  T1.5: 24 ä¸ªé¡¹ç›®\n",
      "  T2: 12 ä¸ªé¡¹ç›®\n",
      "  TX: 17 ä¸ªé¡¹ç›®\n",
      "\n",
      "ğŸ“Š éœ€è¦è®ºæ–‡çš„é¡¹ç›®: 46/76\n",
      "\n",
      "âœ… CS Programs ChromaDB setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Collection statistics and analysis\n",
    "print(\"\\n=== Collection Statistics ===\")\n",
    "print(f\"æ€»é¡¹ç›®æ•°: {collection.count()}\")\n",
    "\n",
    "# Get all data for analysis\n",
    "all_data = collection.get()\n",
    "\n",
    "# Analyze by region\n",
    "regions = [meta['region'] for meta in all_data['metadatas']]\n",
    "region_counts = {}\n",
    "for region in regions:\n",
    "    region_counts[region] = region_counts.get(region, 0) + 1\n",
    "\n",
    "print(\"\\nğŸ“Š æŒ‰åœ°åŒºåˆ†å¸ƒ:\")\n",
    "for region, count in sorted(region_counts.items()):\n",
    "    print(f\"  {region}: {count} ä¸ªé¡¹ç›®\")\n",
    "\n",
    "# Analyze by tier\n",
    "tiers = [meta['tier'] for meta in all_data['metadatas']]\n",
    "tier_counts = {}\n",
    "for tier in tiers:\n",
    "    tier_counts[tier] = tier_counts.get(tier, 0) + 1\n",
    "\n",
    "print(\"\\nğŸ“Š æŒ‰ç­‰çº§åˆ†å¸ƒ:\")\n",
    "for tier, count in sorted(tier_counts.items()):\n",
    "    print(f\"  {tier}: {count} ä¸ªé¡¹ç›®\")\n",
    "\n",
    "# Analyze thesis requirements\n",
    "thesis_required = sum(1 for meta in all_data['metadatas'] if meta['thesis_required'])\n",
    "print(f\"\\nğŸ“Š éœ€è¦è®ºæ–‡çš„é¡¹ç›®: {thesis_required}/{len(all_data['metadatas'])}\")\n",
    "\n",
    "print(\"\\nâœ… CS Programs ChromaDB setup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
